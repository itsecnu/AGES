# AGES: : Self-Attention and GCN Enhanced Audio-Visual Scene Recognition
Notwithstanding the rapid advancements in au-dio-visual scene recognition technology, signif-icant challenges persist. On the one hand, audio and video data contain rich spatial information, necessitating the implementation of feature fu-sion technology to acquire structured infor-mation in space. On the other hand, effective integration of information from existing modali-ties and the design of effective feature extrac-tion and feature fusion strategies are crucial is-sues that audio-visual fusion techniques must address. In addressing these impediments, this paper puts forth AGES: Self-Attention and GCN Enhanced Audio-Visual Scene Recognition Model. The proposed model introduces a cross-modal learning module based on the at-tention mechanism into a GCN fusion network with structured information. The model achieves accurate scene recognition through feature fu-sion of audio and visual modalities. Experi-mental validation was conducted using two standard open datasets TAU and UCF101, and the results demonstrated AGESâ€™s superiority in comparison with other state-of-the-art methods.
